Llm_infos:
  #- {type: Ollama, model: llama3.2:1b, timeout: 40}
  #- {type: Ollama, model: llama3.2, timeout: 60}
  #- {type: Ollama, model: qwen2.5-coder:7b, timeout: 80}
  #- {type: Ollama, model: qwen2.5-coder:14b, timeout: 200}
  #- {type: Ollama, model: phi4, timeout: 150, timeout: 200}
  #- {type: Ollama, model: deepseek-r1:14b, timeout: 300, is_reasoning_model: True}
  
  #- {type: InferenceProvider OpenRouter, model: google/gemini-2.0-flash-001#provider.order/(Google AI Studio)#provider.allow_fallbacks/false, timeout: 60}
  - {type: InferenceProvider OpenRouter, model: google/gemini-2.0-flash-001, timeout: 50}
  #- {type: InferenceProvider OpenRouter, model: google/gemini-2.5-pro-exp-03-25:free, timeout: 80}
  #- {type: InferenceProvider OpenRouter, model: mistralai/mistral-nemo, timeout: 50}
  #- {type: InferenceProvider OpenRouter, model: meta-llama/llama-3.3-70b-instruct, timeout: 50}
  #- {type: InferenceProvider OpenRouter, model: deepseek/deepseek-r1-distill-llama-70b, timeout: 50}
  #- {type: InferenceProvider OpenRouter, model: nousresearch/hermes-3-llama-3.1-405b, timeout: 80}
  #- {type: InferenceProvider OpenRouter, model: mistralai/mistral-large-2411, timeout: 100}
  #- {type: InferenceProvider OpenRouter, model: deepseek/deepseek-chat, timeout: 90}
  #- {type: InferenceProvider OpenRouter, model: deepseek/deepseek-r1, timeout: 90, is_reasoning_model: True}
  - {type: InferenceProvider OpenRouter, model: openai/gpt-4o-mini, timeout: 50}
  #- {type: InferenceProvider OpenRouter, model: openai/gpt-4o, timeout: 50}

  #- {type: OpenAI, model: gpt-3.5-turbo-0125, timeout: 60}
  #- {type: OpenAI, model: gpt-3.5-turbo-instruct, timeout: 60}
  # - {type: OpenAI, model: gpt-4o-mini, timeout: 60}
  # - {type: OpenAI, model: gpt-4o, timeout: 70}

  #- {type: Anthropic, model: claude-3-5-haiku-20241022, timeout: 60}
  #- {type: Anthropic, model: claude-3-5-sonnet-20241022, timeout: 60}
  #- {type: Anthropic, model: claude-3-opus-latest, timeout: 60}

Llms_Temperature: 0.0

Llms_order: [1, 2]